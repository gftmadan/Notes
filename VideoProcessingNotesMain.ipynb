{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b892a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a2741",
   "metadata": {},
   "source": [
    "## OpenCV Provides a `VideoCapture` Class which helps us in Reading and Processing the Videos\n",
    "\n",
    "## We can define a Video as Collection of Frames(Single Image) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751cba85",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42efbf42",
   "metadata": {},
   "source": [
    "# Reading a Image\n",
    "\n",
    "### We use `cv2.VideoCapture()` Constructor to Read a Video and Store it in the Instance Returned by the Constructor.\n",
    "\n",
    "### --->Then we will use the Instance returned to Process the Video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef499c3",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447b132c",
   "metadata": {},
   "source": [
    "## For `cv2.VideoCapture()` Constructor:-\n",
    "\n",
    "### < First Argument > :- It takes the Absolute or Relative File Path. It can also recieve a URL of Video Stream or Image Sequences ,Pipelines etc.\n",
    "### < Second Argument >:- It takes BackEnd API Flags(If we wantt to specify).\n",
    "\n",
    "\n",
    "#### cv2.VideoCapture():-[LINK](https://docs.opencv.org/4.5.4/d8/dfe/classcv_1_1VideoCapture.html#ac4107fb146a762454a8a87715d9b7c96)\n",
    "\n",
    "#### BackEnd API Flags:-[LINK](https://docs.opencv.org/4.5.4/d4/d15/group__videoio__flags__base.html#ga023786be1ee68a9105bf2e48c700294d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598ff5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "song = cv2.VideoCapture(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\Videos\\song.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe852f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.VideoCapture 00000218FF9D3410>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421cb44c",
   "metadata": {},
   "source": [
    "### We can see in the Above Cell that we Read the song Video by passing it Absolute File Path along with extension.\n",
    "\n",
    "### **Note:-We have to Pass the Extension along with File Name ,else it will not be able to read that Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3617c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = cv2.VideoCapture(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\Videos\\abc.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e593ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.VideoCapture 000002C27E2458D0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1f220",
   "metadata": {},
   "source": [
    "### As we can see in the Above Cell we passed wrong name for the Video File ,But it still didnot throw an Error.\n",
    "\n",
    "### Hence we used `< Video Capture Instance >.isOpened()` Method to check whether the Video was Read Successfully and is Ready for Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "301eb2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d543be59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.isOpened()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093840da",
   "metadata": {},
   "source": [
    "### Hence we can see that :-\n",
    "\n",
    "### -->If the Video was Read Successfully then it returns True.\n",
    "### -->If the Video was not Read Succesfully then it returns False. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22cd883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avi = cv2.VideoCapture(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\Videos\\avi.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86e1f520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avi.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "506fd37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flv = cv2.VideoCapture(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\Videos\\flv.flv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8c1f47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flv.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6274d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkv = cv2.VideoCapture(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\Videos\\mkv.mkv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c753f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mkv.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a03a638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mov = cv2.VideoCapture(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\Videos\\mov.mov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6fe3aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfb79409",
   "metadata": {},
   "outputs": [],
   "source": [
    "webm = cv2.VideoCapture(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\Videos\\webm.webm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eec0da96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webm.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f053836",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmv = cv2.VideoCapture(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\Videos\\wmv.wmv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3ddc61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmv.isOpened()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e1aebb",
   "metadata": {},
   "source": [
    "### We can see in the Above Cells that we can read any Type of Video File with the Help of Video Capture Class as long we properly Provide their File Location along with the Proper Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a815fe3",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb491eb",
   "metadata": {},
   "source": [
    "# Accessing Video Capture Properties\n",
    "\n",
    "### As we know that the we get an Instance Of Video Capture which Represents the Readed Video File.\n",
    "\n",
    "### Hence we can acess some Attributes of Video Capture Instance which gives us the Details of the Readed Video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316df8c5",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6c4a48",
   "metadata": {},
   "source": [
    "### --->We use `<Video Capture Instance>.get(<Attribute Name>)` to Get the following Attribute value.\n",
    "\n",
    "### --->We use `<Video Capture Instance>.set(<Attribute Name>,<New Attribute Value>)` to Set the following Attribute Value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43619d30",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541320c6",
   "metadata": {},
   "source": [
    "### List of the `Video Capture Class` Attributes is:-[LINK](https://docs.opencv.org/4.x/d4/d15/group__videoio__flags__base.html#gaeb8dd9c89c10a5c63c139bf7c4f5704d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18595759",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb65a92b",
   "metadata": {},
   "source": [
    "### ~>We will Demonstrate the Use of Some Important Video Capture Attributes:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa62d7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5232.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_count = song.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "frame_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59bd8c0",
   "metadata": {},
   "source": [
    "### This Attribute tells the Total Number of Frames there are in the Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f76b26bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1920.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_width = song.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frame_width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da81eeb",
   "metadata": {},
   "source": [
    "### This Attribute tell the Frame Width present in the Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5a50a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_height = song.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "frame_height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743e9197",
   "metadata": {},
   "source": [
    "### This Attribute tells the Frame Height present in the Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca2887d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps = song.get(cv2.CAP_PROP_FPS)\n",
    "fps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae1db1",
   "metadata": {},
   "source": [
    "### This Attribute tells the FPS of the Video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946fb91e",
   "metadata": {},
   "source": [
    "### ~>We can Calculate the Total Duration of Video in Seconds by using:-\n",
    "### -->Duration = Frame_Count//FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "635d4780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_video_duration(video):\n",
    "    frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    return frame_count//fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd8e51a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_video_duration(song)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668c569f",
   "metadata": {},
   "source": [
    "### We calculated the Video Duration of Song Video and it Fully Correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4ffd87-826a-4871-8416-99fbfeab8a06",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f5143f-1651-4f5a-a12e-68c25098099e",
   "metadata": {},
   "source": [
    "# Processing Frames From Videos\n",
    "\n",
    "## -->We use `cv2.read()` Method to Read the Current Frame from the Video Capture Object(Containing the Video).Some Important Points about `cv2.read()` are:- \n",
    "### 1)It Grabs,Decode and Returns the Next Video Frame(If Available) along with a Boolean Value Incidating whether the Next Frame was Succesfully Grabbed and Returned.\n",
    "### 2)The Next Video Frame is Returned according to the ATTRIBUTE `cv2.CAP_PROP_POS_FRAMES`.This Attribute Corresponds to the Current Frame Position.\n",
    "### 3)It Returns a Tuple Containing Two Elements:-`(Ret,Frame)`.Ret is True if Frame was Succesfully Returned else False."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1539089-7066-4e5a-a24a-e9cfa64ad5f5",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6d684-c84c-406a-b107-8f55de1ca22a",
   "metadata": {},
   "source": [
    "## Before Processing Frames of Video we need to know about Two More Arguments that Corresponds to the Current Frame Postions:-\n",
    "\n",
    "### ---->`cv2.CAP_PROP_POS_FRAMES`:-It Returns the Current Frame Position.\n",
    "### ---->`cv2.CAP_PROP_POS_MSEC`:-It Returns the Current MilliSecond Frame Position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8560669c-c417-4f71-a2bd-eade6551f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video1 = cv2.VideoCapture(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\Videos\\vd1_360.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d56b126-c118-4f2b-b520-783ed2b7663d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video1.get(cv2.CAP_PROP_POS_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57e8a0c6-6971-4581-8ebd-d887d4291f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video1.get(cv2.CAP_PROP_POS_MSEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbec831-f4b5-4050-b0a6-33073fd2a11e",
   "metadata": {},
   "source": [
    "### The Above 0,0 Values are the Initial Starting Points which in Reality dont Corresponds to a Frame.\n",
    "\n",
    "### And In the Cell Below we will call the `read()` Method which will extract Frame of the Next Position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f4d70b6-a7ed-4d6d-ab3c-1d6a4ac0f3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " array([[[102,  36,  36],\n",
       "         [103,  37,  37],\n",
       "         [119,  53,  53],\n",
       "         ...,\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32]],\n",
       " \n",
       "        [[102,  36,  36],\n",
       "         [103,  37,  37],\n",
       "         [119,  53,  53],\n",
       "         ...,\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32]],\n",
       " \n",
       "        [[102,  36,  36],\n",
       "         [103,  37,  37],\n",
       "         [119,  53,  53],\n",
       "         ...,\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         ...,\n",
       "         [ 49,  20,  23],\n",
       "         [ 50,  21,  24],\n",
       "         [ 51,  22,  25]],\n",
       " \n",
       "        [[ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         ...,\n",
       "         [ 49,  20,  23],\n",
       "         [ 50,  21,  24],\n",
       "         [ 51,  22,  25]],\n",
       " \n",
       "        [[ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         ...,\n",
       "         [ 49,  20,  23],\n",
       "         [ 50,  21,  24],\n",
       "         [ 51,  22,  25]]], dtype=uint8))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret,frame = video1.read()\n",
    "ret,frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f6d0819-e55d-4504-a96d-91cb35aa07d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video1.get(cv2.CAP_PROP_POS_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3138213-9c8c-4799-9954-7e9ba02076c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video1.get(cv2.CAP_PROP_POS_MSEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4baa27-0995-4e6f-a81e-0a19cf728575",
   "metadata": {},
   "source": [
    "### In the Above Cells we can see the Extracted the Frame Belonging to Postion:-1 and MilliSeconds:-0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3ed4f94-2896-41b3-85e4-aa80424fc9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " array([[[102,  36,  36],\n",
       "         [103,  37,  37],\n",
       "         [119,  53,  53],\n",
       "         ...,\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32],\n",
       "         [ 79,  35,  31]],\n",
       " \n",
       "        [[102,  36,  36],\n",
       "         [103,  37,  37],\n",
       "         [119,  53,  53],\n",
       "         ...,\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32],\n",
       "         [ 79,  35,  31]],\n",
       " \n",
       "        [[102,  36,  36],\n",
       "         [103,  37,  37],\n",
       "         [119,  53,  53],\n",
       "         ...,\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32],\n",
       "         [ 79,  35,  31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         [ 83,  48,  49],\n",
       "         ...,\n",
       "         [ 50,  21,  24],\n",
       "         [ 51,  22,  25],\n",
       "         [ 51,  22,  25]],\n",
       " \n",
       "        [[ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         [ 83,  48,  49],\n",
       "         ...,\n",
       "         [ 50,  21,  24],\n",
       "         [ 51,  22,  25],\n",
       "         [ 51,  22,  25]],\n",
       " \n",
       "        [[ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         [ 83,  48,  49],\n",
       "         ...,\n",
       "         [ 50,  21,  24],\n",
       "         [ 51,  22,  25],\n",
       "         [ 51,  22,  25]]], dtype=uint8))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret,frame = video1.read()\n",
    "ret,frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85251a12-644d-4917-811f-feaf97de42b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video1.get(cv2.CAP_PROP_POS_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b874d3a6-68e8-4dd7-8897-d5c999c2204e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.36666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video1.get(cv2.CAP_PROP_POS_MSEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634fd9f2-d75b-4339-b85a-5d95b54862cb",
   "metadata": {},
   "source": [
    "### In the Above Cells we can see the Extracted the Frame Belonging to Postion:-2 and MilliSeconds:-33.3666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6dd6316-5e2e-4e89-acef-35d6fa4fb6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " array([[[102,  36,  36],\n",
       "         [103,  37,  37],\n",
       "         [119,  53,  53],\n",
       "         ...,\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32],\n",
       "         [ 79,  35,  31]],\n",
       " \n",
       "        [[102,  36,  36],\n",
       "         [103,  37,  37],\n",
       "         [119,  53,  53],\n",
       "         ...,\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32],\n",
       "         [ 79,  35,  31]],\n",
       " \n",
       "        [[102,  36,  36],\n",
       "         [103,  37,  37],\n",
       "         [119,  53,  53],\n",
       "         ...,\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32],\n",
       "         [ 79,  35,  31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         [ 83,  48,  49],\n",
       "         ...,\n",
       "         [ 49,  21,  21],\n",
       "         [ 50,  22,  22],\n",
       "         [ 51,  23,  23]],\n",
       " \n",
       "        [[ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         [ 83,  48,  49],\n",
       "         ...,\n",
       "         [ 49,  21,  21],\n",
       "         [ 50,  22,  22],\n",
       "         [ 51,  23,  23]],\n",
       " \n",
       "        [[ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         [ 83,  48,  49],\n",
       "         ...,\n",
       "         [ 49,  21,  21],\n",
       "         [ 50,  22,  22],\n",
       "         [ 51,  23,  23]]], dtype=uint8))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret,frame = video1.read()\n",
    "ret,frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e8dcc80-b02a-492d-b68e-d786a2ca94b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video1.get(cv2.CAP_PROP_POS_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f49e786b-e589-4b0a-9077-d6dba71a0916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.73333333333333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video1.get(cv2.CAP_PROP_POS_MSEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee82de7-69d1-4d6c-b32b-6e80af74976a",
   "metadata": {},
   "source": [
    "### In the Above Cells we can see the Extracted the Frame Belonging to Postion:-2 and MilliSeconds:-33.3666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0c8c48d-d140-4ccd-a947-bc30c7731058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " array([[[102,  36,  36],\n",
       "         [103,  37,  37],\n",
       "         [119,  53,  53],\n",
       "         ...,\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32],\n",
       "         [ 79,  35,  31]],\n",
       " \n",
       "        [[102,  36,  36],\n",
       "         [103,  37,  37],\n",
       "         [119,  53,  53],\n",
       "         ...,\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32],\n",
       "         [ 79,  35,  31]],\n",
       " \n",
       "        [[102,  36,  36],\n",
       "         [103,  37,  37],\n",
       "         [119,  53,  53],\n",
       "         ...,\n",
       "         [ 80,  36,  32],\n",
       "         [ 80,  36,  32],\n",
       "         [ 79,  35,  31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         [ 83,  48,  49],\n",
       "         ...,\n",
       "         [ 49,  21,  21],\n",
       "         [ 49,  21,  21],\n",
       "         [ 51,  23,  23]],\n",
       " \n",
       "        [[ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         [ 83,  48,  49],\n",
       "         ...,\n",
       "         [ 49,  21,  21],\n",
       "         [ 49,  21,  21],\n",
       "         [ 51,  23,  23]],\n",
       " \n",
       "        [[ 82,  47,  48],\n",
       "         [ 82,  47,  48],\n",
       "         [ 83,  48,  49],\n",
       "         ...,\n",
       "         [ 49,  21,  21],\n",
       "         [ 49,  21,  21],\n",
       "         [ 51,  23,  23]]], dtype=uint8))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret,frame = video1.read()\n",
    "ret,frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d23d7fb4-8677-4fad-9d94-443be17c25f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video1.get(cv2.CAP_PROP_POS_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5f73165-c8c5-41e7-8edb-e8ab4ac69797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.10000000000001"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video1.get(cv2.CAP_PROP_POS_MSEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1053a51-085e-463b-8a0c-66105145e84f",
   "metadata": {},
   "source": [
    "### In the Above Cells we can see the Extracted the Frame Belonging to Postion:-2 and MilliSeconds:-33.3666\n",
    "\n",
    "## We can notice in the Above Cells that Amount to Process each Frame is 33.36 milliseconds which we can also Calculate by 1000/VideoFPS.\n",
    "\n",
    "## `And The Same Pattern Will Continue As we Further On Extract Frames`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e37f0a-b402-46ed-aef5-d3e202080015",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d467ec4-45b3-4399-8446-3e80e22f1ff0",
   "metadata": {},
   "source": [
    "# Displaying and Processing the Full Video Frame by Frame\n",
    "\n",
    "### In the Below Cell we will use `while` loop to Iterate Over Each Frame and also get its Position Number and Position Millisecond Arguments,Then Store each Frame as Image in the OUTPUT DIRECTORY with Name containing information of Both Above Specified Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9916d92c-9050-4bc5-91d7-d863add06410",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR  = r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\OutputData\\Video1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c8b47d9-0c83-4eec-a2ee-dc3784890e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "video1 = cv2.VideoCapture(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\Videos\\vd1_360.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec95778f-62a4-43bd-a664-e6aebdbe9127",
   "metadata": {},
   "outputs": [],
   "source": [
    "while video1.isOpened():\n",
    "    ret,frame = video1.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    frame_pos = int(video1.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "    frame_ms = int(video1.get(cv2.CAP_PROP_POS_MSEC))\n",
    "    image_loc = os.path.join(OUTPUT_DIR,f\"FR{frame_pos}__MS{frame_ms}.png\")\n",
    "    cv2.imwrite(image_loc,frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e0c1e3-2bae-4e6d-89a6-d0aea0755f53",
   "metadata": {},
   "source": [
    "### We can notice the Extracted Frame Images in the OUTPUT DIRECTORY and we can see it was correctly Extracted and Processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eed24a-2d9c-4d9c-b813-7eefbbd821c4",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bbbf60-cad5-4c3b-8aaa-6952680f30df",
   "metadata": {},
   "source": [
    "# Writing Video to Disk\n",
    "\n",
    "### We use `cv2.VideoWriter` Class to write Video to a Disk.In order to write a Video we should provide Images Frame by Frame to the Video Writer Instance from which we want to Write the Video.\n",
    "\n",
    "## For `cv2.VideoWriter()` Method:-\n",
    "\n",
    "### < First Argument >(File Name):-It takes the File Name which should Specify the Absolute Location were we want to save the Video.\n",
    "### < Second Argument >(Fourcc Code):-It takes the 4-character Code of Codec used to Compress the Frames.\n",
    "### < Third Argument >(FPS):-It takes the Frame Per Second we want our Video to Have.\n",
    "### < Fourth Argument >(Frame Size):-It takes a Collection of (Width,Height) which we want our Video to be.\n",
    "### < Fifth Argument >(isColor):-It take a Boolean.If `True` then it will Encode the Frame in Colored Format else it will Encode the Frame in GrayScale Format.\n",
    "\n",
    "## In the Example Below we will be Constructing a Video using 10 Images with each Image having a Specfic Duration of Time in the Full Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aec8295d-4b5b-4001-bde0-0aa22e895b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSTRUCTING_VIDEO_LOC = r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\ConstructVideo\"\n",
    "FPS = 30\n",
    "SECOND_FOR_EACH_IMAGE = 2\n",
    "OUTPUT_VIDEO_LOC = r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\OutputData\\VideoWrite.avi\"\n",
    "fourcc = fourcc = cv2.VideoWriter_fourcc('M','P','4','S')\n",
    "frame_width = 720\n",
    "frame_height = 1080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba976dcf-2c92-4333-8bd8-a68cacdec2b9",
   "metadata": {},
   "source": [
    "### In the Above Cell we have Set the Main Values Which will Help us in Writing the Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59dd9a85-276a-46be-a312-bfb593836109",
   "metadata": {},
   "outputs": [],
   "source": [
    "videowriter = cv2.VideoWriter(OUTPUT_VIDEO_LOC,fourcc,FPS,(frame_width,frame_height),isColor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd56f4b7-27a5-452a-8a74-b5e5713bbc27",
   "metadata": {},
   "source": [
    "### In the Above Cell we have defined out Video Writer Instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "382624b2-57c8-4e76-b7d1-7ec5af3bef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in os.listdir(CONSTRUCTING_VIDEO_LOC):\n",
    "    img_loc = os.path.join(CONSTRUCTING_VIDEO_LOC,img)\n",
    "    image = cv2.imread(img_loc)\n",
    "    image = cv2.resize(image,(frame_width,frame_height))\n",
    "    for _ in range(SECOND_FOR_EACH_IMAGE*FPS):\n",
    "        videowriter.write(image)\n",
    "videowriter.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6976b272-3c37-4db8-910c-9535831734d4",
   "metadata": {},
   "source": [
    "### We can see in the OUTPUT DIRECTORY that the Video was Written Succesfully in the Desired Manner we wanted.\n",
    "\n",
    "\n",
    "## **Note:-While Writing a Video please check whether the Fourcc Code we are Using is Installed on our Window else we will be not able to View the Video on the Computer. \n",
    "\n",
    "### How To Check what CodeX(Fourcc Code) are Installed on my System:-https://www.thewindowsclub.com/how-to-check-installed-codecs-on-windows-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751c549-17b7-4663-b36e-fd9495a887dc",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb2e07-9d4a-4735-80f8-77d358e85190",
   "metadata": {},
   "source": [
    "# Cutting Video According to TimeStamps\n",
    "\n",
    "### We can Acess a Specfic Frame in the Video according to its Position using `cv2.CAP_PROP_POS_FRAMES`.\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b345b388-ae92-413d-9b40-d0850a72cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "video1 = cv2.VideoCapture(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\Videos\\vd1_360.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "72788ebd-a73e-4c37-ae1b-9732a4bfbfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video1.set(cv2.CAP_PROP_POS_MSEC,1034)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ef97891-e2d2-49e0-a30c-bccbd9bdd34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,frame = video1.read()\n",
    "cv2.imshow(\"Frame\",frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "26673235-36fb-4483-94b4-6ccabfc3810c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video1.get(cv2.CAP_PROP_POS_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "55658d3d-bfcc-4f80-8c29-df187bd83923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034.3666666666666"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video1.get(cv2.CAP_PROP_POS_MSEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b505968c-c0d8-47a4-96ec-55e8ec826672",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\OutputData\\fg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "193fc40a-aabc-49c8-a485-a4e7be8f72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = cv2.VideoCapture(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\Videos\\vd2_360.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "14895234-253e-42f1-8f5c-51176c7e7ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "while v1.isOpened():\n",
    "    ret,frame = v1.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    frame_pos = int(v1.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "    frame_ms = int(v1.get(cv2.CAP_PROP_POS_MSEC))\n",
    "    image_loc = os.path.join(OUTPUT_DIR,f\"FR{frame_pos}__MS{frame_ms}.png\")\n",
    "    cv2.imwrite(image_loc,frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7cbf832-e99e-4b9b-8f5a-d29385d009af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.set(cv2.CAP_PROP_POS_MSEC,1733)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "90532b13-294b-4652-8c0a-a5e4582180da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.get(cv2.CAP_PROP_POS_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c3461-b5b9-4a00-be3d-7de750834c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cfd3468f-14eb-4d63-9e71-a16faecd3c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,frame = v1.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c7bb2fea-a201-4390-b761-7561c03523d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.get(cv2.CAP_PROP_POS_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2fe9f1f5-1ca6-4f7b-b469-8ab88402cc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.set(cv2.CAP_PROP_POS_FRAMES,54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cba2613e-7463-4a12-9477-56fa9f5c892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = cv2.VideoCapture(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\Videos\\vd2_360.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f04afd1c-3174-4534-8ad5-9dfa7ae4acdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.get(cv2.CAP_PROP_POS_MSEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edca56a-c513-4b50-83fc-e4fa64e4eafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9533232a-67ca-4850-b2bd-b55b2c517b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.get(cv2.CAP_PROP_POS_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c2b6de9e-f3a7-49d2-89c5-d2a5741603cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,frame = v1.read()\n",
    "cv2.imshow(\"Output\",frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc3e7bc5-941f-4f7f-8a25-a3f141c1572c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3606.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.get(cv2.CAP_PROP_FRAME_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829e2fac-43c5-4b88-9047-43ff4af68e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d67e5c-26d9-4a1c-89d3-2e20746742d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb6f1f23-b89f-4183-a665-c88ae9009fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "while song.isOpened():\n",
    "    ret,frame = song.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    cv2.namedWindow(\"Video\",cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"Video\",frame)\n",
    "    cv2.resizeWindow(\"Video\",(500,500))\n",
    "    key = cv2.waitKey(25)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e2a1248-71df-4eb4-97f4-0cc0574b5b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song.get(cv2.CAP_PROP_POS_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db1472c1-eebe-4778-b77f-831fcaec359b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8e-05"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(song.get(cv2.CAP_PROP_POS_AVI_RATIO),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e27061f6-3949-4311-bc23-e09dbaae3022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35875.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song.get(cv2.CAP_PROP_POS_MSEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54e31452-ce48-4b55-bd54-c957b600c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_position(ms):\n",
    "    sec = float(ms)/1000.0\n",
    "    tm = time.gmtime(sec)\n",
    "    hours = tm.tm_hour\n",
    "    mins = tm.tm_min\n",
    "    secs = tm.tm_sec\n",
    "    return hours,mins,secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51cef195-e60d-4793-b201-cb8be5b5cfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 35)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_position(song.get(cv2.CAP_PROP_POS_MSEC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa8cb56c-1307-448e-96a9-d884f392eca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3, 38)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_position(218*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd625f1-3649-4aea-904e-2afe48b6eb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e91c7e7d-e505-4925-b662-30d01e2a0a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35875.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms = song.get(cv2.CAP_PROP_POS_MSEC)\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "836cc237-6916-4f31-9a05-23b1b5a7db16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm = song.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d080ef57-1041-4c0c-a87a-016027042997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps = song.get(cv2.CAP_PROP_FPS)\n",
    "fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "44314c96-a003-4690-b260-b666390f8655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "862//24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "25ff0e10-4070-4b63-aa6d-615ab76dfaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.875"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c09ef56c-cbbb-45eb-b431-10953b282624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_sec = 2 * 60 + 50\n",
    "start_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7f7621c5-0620-4e88-9e73-3fbedc99daa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_sec = 3 * 60 + 10\n",
    "end_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8e3c81ba-9a43-476b-8974-e7d216b1d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_frame = int(start_sec * fps)\n",
    "end_frame = int(end_sec * fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "24b4fe73-2ff1-432c-aaa6-ab6e588bd566",
   "metadata": {},
   "outputs": [],
   "source": [
    "song.set(cv2.CAP_PROP_POS_FRAMES,strat_frame)\n",
    "for i in range(strat_frame,end_frame):\n",
    "    ret,frame = song.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    cv2.namedWindow(\"Video\",cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Video\",(600,600))\n",
    "    cv2.imshow(\"Video\",frame)\n",
    "    key = cv2.waitKey(28)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b3530-0ed2-43d7-beeb-5711996717ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5eec37-5956-477f-888b-8e95bddc1d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3036f-08c6-46e6-8a8c-66d0b3445258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14971f46-a96b-40d1-ba8d-87519e5e4b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "seconds = 218\n",
    "\n",
    "td = datetime.timedelta(seconds=218)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55a7158f-c7dd-4834-9490-154f262fe17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=218)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0919249-550c-4ad2-b829-03da07a2036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tm = time.gmtime(218)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d07047e3-cf6c-446c-ac51-07489b6f245a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time.struct_time(tm_year=1970, tm_mon=1, tm_mday=1, tm_hour=0, tm_min=3, tm_sec=38, tm_wday=3, tm_yday=1, tm_isdst=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37741c9f-0a72-4a2a-a70e-95114cafff0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03:38'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.strftime(\"%M:%S\",tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52b92c23-b03e-4982-8f87-e6ecf7487e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.tm_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19eaf90f-07de-48ff-9e0a-a42aae7c9e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([3,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e2824b-df6a-4b4e-96db-b2fcaa8a9ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
