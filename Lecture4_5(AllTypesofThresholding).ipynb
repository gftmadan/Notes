{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ec94e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cca42c",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1798279b",
   "metadata": {},
   "source": [
    "# Image Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5000b4ee",
   "metadata": {},
   "source": [
    "## Thresholding is one of the most common (and basic) segmentation techniques in computer vision and it allows us to separate the foreground (i.e., the objects that we are interested in) from the background of the image.\n",
    "\n",
    "## Thresholding is mainly of Three Types:-\n",
    "\n",
    "### 1)Simple Thresholding\n",
    "### 2)OTSU Thresholding\n",
    "### 3)Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dff30b",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac52ab",
   "metadata": {},
   "source": [
    "## -->Simple Thresholding\n",
    "\n",
    "### Its also termed as BINARY Thresholding.\n",
    "### In this Technique we Manually set a Standard Threshold Value(T) and each Pixel of the Image is compared with the Threshold Value(T).\n",
    "### -->If the Pixel Value is Less than T then that Pixel Value is set to 0 in the Output Image.\n",
    "### -->If the Pixel Value is Greater than T then that Pixel Value is set to the Maximum Value(Provided in the Method Argument as THIRD Argument) OR Some Value depending on the THRESHOLDING TYPE.\n",
    "### It works very well in a Controlled Lighting Conditions where we can Ensure High Contrast between Background and Foreground.\n",
    "\n",
    "### To perform Simple Threshold we use `cv2.threshold()` Method.\n",
    "\n",
    "## For `cv2.threshold()` :-\n",
    "\n",
    "### < First Argument >:-It takes the NUMPY Array of the Input Image.\n",
    "### < Second Argument >:-It takes the Threshold Value(T).\n",
    "### < Third Argument >:-It takes the Maximum Value(Only Used for THRESH_BINARY or THRESH_BINARY_INV) .\n",
    "### < Fourth Argument >:-It takes the THRESHOLDING TYPE Flags. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae980d5b",
   "metadata": {},
   "source": [
    "#### cv2.threshold():-[LINK](https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57)\n",
    "\n",
    "#### THRESHOLDING Type FLAGS:-[LINK](https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#gaa9e58d2860d4afa658ef70a9b1115576)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9969f4",
   "metadata": {},
   "source": [
    "## Simpe Thresholding can also be sub-divided according to the THRESHOLDING TYPE Flag being used:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2461695b",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4c1930",
   "metadata": {},
   "source": [
    "### Thresh Binary\n",
    "\n",
    "### In this each Pixel Value of the Input Image is compared to the Threshold Value(T) And If:-\n",
    "### -->The Pixel Value is Greater than T then it Outputs to the Maximum Value(Provided in the Third Argument).\n",
    "### -->The Pixel Value is Less than or Equal to T then it Outputs to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e309c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn1color = cv2.imread(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\coins1.png\")\n",
    "cn1gray = cv2.cvtColor(cn1color,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5913b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Colored Image\",cn1color)\n",
    "cv2.imshow(\"Graye Scale Image\",cn1gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "433b924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TB1gray = cv2.threshold(cn1gray,180,255,cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7320021f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180.0,\n",
       " array([[255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255]], dtype=uint8))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TB1gray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955aa87d",
   "metadata": {},
   "source": [
    "### We can see It Returns a Tuple containing:-\n",
    "### -->Threshold Value as First Argument.\n",
    "### -->Thresh Binary Image as Second Argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b827ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Gray Scale Image\",cn1gray)\n",
    "cv2.imshow(\"Threshold Binary GrayScale Image\",TB1gray[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f30829",
   "metadata": {},
   "source": [
    "### We can see we Performed THRESH Binary Simple Thresholding(with T =180) on Gray Scale Image and got the Expected Results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5902f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TB1color = cv2.threshold(cn1color,180,255,cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "875f29f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180.0,\n",
       " array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TB1color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "215ce85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Colored Image\",cn1color)\n",
    "cv2.imshow(\"Threshold Binary Colored Image\",TB1color[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3861f",
   "metadata": {},
   "source": [
    "### We can see we Performed Thresh Binary Simple Thresholding(with T=180) on an Color Image and got an Unexpected Result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6874897",
   "metadata": {},
   "source": [
    "### As we can see we got Better Results when Performed Thresholding on Gray Scale Image So Performing Following Tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c1cf799",
   "metadata": {},
   "outputs": [],
   "source": [
    "TB1_240 = cv2.threshold(cn1gray,240,255,cv2.THRESH_BINARY)\n",
    "TB1_220 = cv2.threshold(cn1gray,220,255,cv2.THRESH_BINARY)\n",
    "TB1_200 = cv2.threshold(cn1gray,200,255,cv2.THRESH_BINARY)\n",
    "TB1_180 = cv2.threshold(cn1gray,180,255,cv2.THRESH_BINARY)\n",
    "TB1_150= cv2.threshold(cn1gray,150,255,cv2.THRESH_BINARY)\n",
    "TB1_130 = cv2.threshold(cn1gray,130,255,cv2.THRESH_BINARY)\n",
    "TB1_110 = cv2.threshold(cn1gray,110,255,cv2.THRESH_BINARY)\n",
    "TB1_90 = cv2.threshold(cn1gray,90,255,cv2.THRESH_BINARY)\n",
    "TB1_50 = cv2.threshold(cn1gray,50,255,cv2.THRESH_BINARY)\n",
    "TB1_30 = cv2.threshold(cn1gray,30,255,cv2.THRESH_BINARY)\n",
    "TB1_10 = cv2.threshold(cn1gray,10,255,cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dc36728",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Normal Image\",cn1gray)\n",
    "cv2.imshow(\"fg240\",TB1_240[1])\n",
    "cv2.imshow(\"fg220\",TB1_220[1])\n",
    "cv2.imshow(\"fg200\",TB1_200[1])\n",
    "cv2.imshow(\"fg180\",TB1_180[1])\n",
    "cv2.imshow(\"fg150\",TB1_150[1])\n",
    "cv2.imshow(\"fg110\",TB1_110[1])\n",
    "cv2.imshow(\"fg90\",TB1_90[1])\n",
    "cv2.imshow(\"fg50\",TB1_50[1])\n",
    "cv2.imshow(\"fg30\",TB1_30[1])\n",
    "cv2.imshow(\"fg10\",TB1_10[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c03e84",
   "metadata": {},
   "source": [
    "### We can see how Different Threshold Value Affects the Output Image for Simple Binary Thresholding on Gray Scale Image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecbc737",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7fa902",
   "metadata": {},
   "source": [
    "## Thresh Binary Inverse\n",
    "\n",
    "### In this each Pixel Value of the Image Is Compared to the Threshold Value(T) And If:-\n",
    "### -->The Pixel Value is Greater than T then it output to 0.\n",
    "### -->The Pixel Value is Less than T then it Outputs to the Maximum Value.(Provided in the Third Argument).\n",
    "\n",
    "### **Note:-Its the opposite of the THRESH Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da069d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "TBI1_gray = cv2.threshold(cn1gray,180,255,cv2.THRESH_BINARY_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b3e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Normal GrayScale Image\",cn1gray)\n",
    "cv2.imshow(\"Threshold Binary Inverse\",TBI1_gray[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2822d4a0",
   "metadata": {},
   "source": [
    "### We performed Simple Binary Inverse Threshold(with T =180) on a Gray Scale Image and Obtained the result as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a889a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TBI1_color = cv2.threshold(cn1color,180,255,cv2.THRESH_BINARY_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2df18ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Normal Colored Image\",cn1color)\n",
    "cv2.imshow(\"Threshold Binary Inverse Colored Image\",TBI1_color[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa69609",
   "metadata": {},
   "source": [
    "### We performed Simple Binary Inverse Threshold(with T=180) on Colored Image and Obtained Unexpected Results\n",
    "\n",
    "### As we can see we got Better and Expected Results on performing Simple Binary Inverse Thresholding hence Performing the following Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2acd3804",
   "metadata": {},
   "outputs": [],
   "source": [
    "TBI1_250 = cv2.threshold(cn1gray,250,255,cv2.THRESH_BINARY_INV)\n",
    "TBI1_225 = cv2.threshold(cn1gray,225,255,cv2.THRESH_BINARY_INV)\n",
    "TBI1_200 = cv2.threshold(cn1gray,200,255,cv2.THRESH_BINARY_INV)\n",
    "TBI1_180 = cv2.threshold(cn1gray,180,255,cv2.THRESH_BINARY_INV)\n",
    "TBI1_160 = cv2.threshold(cn1gray,160,255,cv2.THRESH_BINARY_INV)\n",
    "TBI1_140 = cv2.threshold(cn1gray,140,255,cv2.THRESH_BINARY_INV)\n",
    "TBI1_120 = cv2.threshold(cn1gray,120,255,cv2.THRESH_BINARY_INV)\n",
    "TBI1_100 = cv2.threshold(cn1gray,100,255,cv2.THRESH_BINARY_INV)\n",
    "TBI1_80 = cv2.threshold(cn1gray,80,255,cv2.THRESH_BINARY_INV)\n",
    "TBI1_50 = cv2.threshold(cn1gray,50,255,cv2.THRESH_BINARY_INV)\n",
    "TBI1_30 = cv2.threshold(cn1gray,30,255,cv2.THRESH_BINARY_INV)\n",
    "TBI1_10 = cv2.threshold(cn1gray,10,255,cv2.THRESH_BINARY_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d18a7818",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"TBI1_250\",TBI1_250[1])\n",
    "cv2.imshow(\"TBI1_225\",TBI1_225[1])\n",
    "cv2.imshow(\"TBI1_200\",TBI1_200[1])\n",
    "cv2.imshow(\"TBI1_180\",TBI1_180[1])\n",
    "cv2.imshow(\"TBI1_160\",TBI1_160[1])\n",
    "cv2.imshow(\"TBI1_140\",TBI1_140[1])\n",
    "cv2.imshow(\"TBI1_120\",TBI1_120[1])\n",
    "cv2.imshow(\"TBI1_100\",TBI1_100[1])\n",
    "cv2.imshow(\"TBI1_80\",TBI1_80[1])\n",
    "cv2.imshow(\"TBI1_50\",TBI1_50[1])\n",
    "cv2.imshow(\"TBI1_30\",TBI1_30[1])\n",
    "cv2.imshow(\"TBI1_10\",TBI1_10[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c616a0d9",
   "metadata": {},
   "source": [
    "### We can see in the Above Cells how Different Vaue of Threshold can affect the Results when performing Simple Binary Inverse Thresholding on Gray Scale Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9a2940",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981b23c",
   "metadata": {},
   "source": [
    "## Thresh Trunc\n",
    "\n",
    "### In this each Pixel Value of the Image Is Compared to the Threshold Value(T) And If:-\n",
    "### -->The Pixel Value is Greater than T then it output to T.\n",
    "### -->The Pixel Value is Less than T then it doesnot Changes its Value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76eb066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TT1_gray = cv2.threshold(cn1gray,180,255,cv2.THRESH_TRUNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1c593ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Gray Scale Image\",cn1gray)\n",
    "cv2.imshow(\"Thresh Trunc GrayScale Image\",TT1_gray[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99670642",
   "metadata": {},
   "source": [
    "### We performed Simple Trunc Thresholding(with T=180) on Gray Scale Image and Obtained Expected Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab5207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TT1_color = cv2.threshold(cn1color,180,255,cv2.THRESH_TRUNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71fe4413",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Colored Image\",cn1color)\n",
    "cv2.imshow(\"Thresh Trunc Colored Image\",TT1_color[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c295f77",
   "metadata": {},
   "source": [
    "### We performed Simple Trunc Thresholding(with T=180) on Colored Image and Obtain UnExpected Result\n",
    "\n",
    "### As we can see we got Better and Expected Result on GrayScale Images hence Performing the Following Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0971fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TT1_250 = cv2.threshold(cn1gray,250,255,cv2.THRESH_TRUNC)\n",
    "TT1_220 = cv2.threshold(cn1gray,220,255,cv2.THRESH_TRUNC)\n",
    "TT1_200 = cv2.threshold(cn1gray,200,255,cv2.THRESH_TRUNC)\n",
    "TT1_180 = cv2.threshold(cn1gray,180,255,cv2.THRESH_TRUNC)\n",
    "TT1_160 = cv2.threshold(cn1gray,160,255,cv2.THRESH_TRUNC)\n",
    "TT1_140 = cv2.threshold(cn1gray,140,255,cv2.THRESH_TRUNC)\n",
    "TT1_120 = cv2.threshold(cn1gray,120,255,cv2.THRESH_TRUNC)\n",
    "TT1_100 = cv2.threshold(cn1gray,100,255,cv2.THRESH_TRUNC)\n",
    "TT1_80 = cv2.threshold(cn1gray,80,255,cv2.THRESH_TRUNC)\n",
    "TT1_50 = cv2.threshold(cn1gray,50,255,cv2.THRESH_TRUNC)\n",
    "TT1_30 = cv2.threshold(cn1gray,30,255,cv2.THRESH_TRUNC)\n",
    "TT1_10 = cv2.threshold(cn1gray,10,255,cv2.THRESH_TRUNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09fcf8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"TT1_250\",TT1_250[1])\n",
    "cv2.imshow(\"TT1_220\",TT1_220[1])\n",
    "cv2.imshow(\"TT1_200\",TT1_200[1])\n",
    "cv2.imshow(\"TT1_180\",TT1_180[1])\n",
    "cv2.imshow(\"TT1_160\",TT1_160[1])\n",
    "cv2.imshow(\"TT1_140\",TT1_140[1])\n",
    "cv2.imshow(\"TT1_120\",TT1_120[1])\n",
    "cv2.imshow(\"TT1_100\",TT1_100[1])\n",
    "cv2.imshow(\"TT1_80\",TT1_80[1])\n",
    "cv2.imshow(\"TT1_50\",TT1_50[1])\n",
    "cv2.imshow(\"TT1_30\",TT1_30[1])\n",
    "cv2.imshow(\"TT1_10\",TT1_10[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0667307",
   "metadata": {},
   "source": [
    "### We can see in the Above Cells that how Different Threshold Value while performing Simple Thrunc Thresholding can affect the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a061580",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaf1b60",
   "metadata": {},
   "source": [
    "## Thresh To Zero\n",
    "\n",
    "### In this each Pixel Value of the Image Is Compared to the Threshold Value(T) And If:-\n",
    "### -->The Pixel Value is Greater than T then it doesnot Changes its Value.\n",
    "### -->The Pixel Value is Less than T then it Outputs to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e80e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "TZ1_gray = cv2.threshold(cn1gray,180,255,cv2.THRESH_TOZERO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abf0aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Normal Gray Scale Image\",cn1gray)\n",
    "cv2.imshow(\"Thresh To Zero Gray Scale Image\",TZ1_gray[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532bbb94",
   "metadata": {},
   "source": [
    "### We performed Simple Thresh To Zero Thresholding(with T=180) on Gray Scale Image and got Expected Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e98772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TZ1_color = cv2.threshold(cn1color,180,255,cv2.THRESH_TOZERO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54bdb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Normal Colored Image\",cn1color)\n",
    "cv2.imshow(\"Thresh To Zero Colored Image\",TZ1_color[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940eb111",
   "metadata": {},
   "source": [
    "### We performed Simple Thresh To Zerp Thresholding(with T=180) on Colored Image and got the UnExpected Results\n",
    "\n",
    "### As we can see we got Better and Expected Results on GrayScale Images hence performing following Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03db57ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "TZ1_250 = cv2.threshold(cn1gray,250,255,cv2.THRESH_TOZERO)\n",
    "TZ1_220 = cv2.threshold(cn1gray,220,255,cv2.THRESH_TOZERO)\n",
    "TZ1_200 = cv2.threshold(cn1gray,200,255,cv2.THRESH_TOZERO)\n",
    "TZ1_180 = cv2.threshold(cn1gray,180,255,cv2.THRESH_TOZERO)\n",
    "TZ1_160 = cv2.threshold(cn1gray,160,255,cv2.THRESH_TOZERO)\n",
    "TZ1_140 = cv2.threshold(cn1gray,140,255,cv2.THRESH_TOZERO)\n",
    "TZ1_120 = cv2.threshold(cn1gray,120,255,cv2.THRESH_TOZERO)\n",
    "TZ1_100 = cv2.threshold(cn1gray,100,255,cv2.THRESH_TOZERO)\n",
    "TZ1_80 = cv2.threshold(cn1gray,80,255,cv2.THRESH_TOZERO)\n",
    "TZ1_60 = cv2.threshold(cn1gray,60,255,cv2.THRESH_TOZERO)\n",
    "TZ1_50 = cv2.threshold(cn1gray,50,255,cv2.THRESH_TOZERO)\n",
    "TZ1_30 = cv2.threshold(cn1gray,30,255,cv2.THRESH_TOZERO)\n",
    "TZ1_10 = cv2.threshold(cn1gray,10,255,cv2.THRESH_TOZERO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b7992a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"TZ1_250\",TZ1_250[1])\n",
    "cv2.imshow(\"TZ1_220\",TZ1_220[1])\n",
    "cv2.imshow(\"TZ1_200\",TZ1_200[1])\n",
    "cv2.imshow(\"TZ1_180\",TZ1_180[1])\n",
    "cv2.imshow(\"TZ1_160\",TZ1_160[1])\n",
    "cv2.imshow(\"TZ1_140\",TZ1_140[1])\n",
    "cv2.imshow(\"TZ1_120\",TZ1_120[1])\n",
    "cv2.imshow(\"TZ1_100\",TZ1_100[1])\n",
    "cv2.imshow(\"TZ1_80\",TZ1_80[1])\n",
    "cv2.imshow(\"TZ1_60\",TZ1_60[1])\n",
    "cv2.imshow(\"TZ1_50\",TZ1_50[1])\n",
    "cv2.imshow(\"TZ1_30\",TZ1_30[1])\n",
    "cv2.imshow(\"TZ1_10\",TZ1_10[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c21474",
   "metadata": {},
   "source": [
    "### We can see in Above Cells that how Different Threshold Value in Simple Tresh To Zero can affect Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5289fe",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d08d463",
   "metadata": {},
   "source": [
    "## Thresh To Zero Inverse\n",
    "\n",
    "### In this each Pixel Value of the Image Is Compared to the Threshold Value(T) And If:-\n",
    "### -->The Pixel Value is Greater than T then it Outputs to 0.\n",
    "### -->The Pixel Value is Less than T then it doesnot Changes.\n",
    "\n",
    "### **NOTE:-Its the opposite of THRESH To Zero Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db239c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TTZI1_gray = cv2.threshold(cn1gray,180,255,cv2.THRESH_TOZERO_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16b4ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Gray Scale Image\",cn1gray)\n",
    "cv2.imshow(\"Thresh To Zero Gray Scale Image\",TTZI1_gray[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897406e2",
   "metadata": {},
   "source": [
    "### We have performed Simple Thresh To Zero Thresholding(with T=180) on a Gray Scale Image and got the Expected Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2639efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TTZI1_color = cv2.threshold(cn1color,180,255,cv2.THRESH_TOZERO_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "667ccc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Normal Colored Image\",cn1color)\n",
    "cv2.imshow(\"Thresh To Zero Colored Image\",TTZI1_color[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aea2ba",
   "metadata": {},
   "source": [
    "### We have performed Simple Thresh To Zero Thresholding(with T=180) on a Colored Image and got UnExpected Results\n",
    "\n",
    "### As we can see that we got Better and Expected Results on Gray Scale Images hence performing the following tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66bf2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "TTZI_250 = cv2.threshold(cn1gray,250,255,cv2.THRESH_TOZERO_INV)\n",
    "TTZI_240 = cv2.threshold(cn1gray,240,255,cv2.THRESH_TOZERO_INV)\n",
    "TTZI_220 = cv2.threshold(cn1gray,220,255,cv2.THRESH_TOZERO_INV)\n",
    "TTZI_200 = cv2.threshold(cn1gray,200,255,cv2.THRESH_TOZERO_INV)\n",
    "TTZI_180 = cv2.threshold(cn1gray,180,255,cv2.THRESH_TOZERO_INV)\n",
    "TTZI_160 = cv2.threshold(cn1gray,160,255,cv2.THRESH_TOZERO_INV)\n",
    "TTZI_140 = cv2.threshold(cn1gray,140,255,cv2.THRESH_TOZERO_INV)\n",
    "TTZI_120 = cv2.threshold(cn1gray,120,255,cv2.THRESH_TOZERO_INV)\n",
    "TTZI_100 = cv2.threshold(cn1gray,100,255,cv2.THRESH_TOZERO_INV)\n",
    "TTZI_80 = cv2.threshold(cn1gray,80,255,cv2.THRESH_TOZERO_INV)\n",
    "TTZI_50 = cv2.threshold(cn1gray,50,255,cv2.THRESH_TOZERO_INV)\n",
    "TTZI_30 = cv2.threshold(cn1gray,30,255,cv2.THRESH_TOZERO_INV)\n",
    "TTZI_10 = cv2.threshold(cn1gray,10,255,cv2.THRESH_TOZERO_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05bedd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"TTZI1_250\",TTZI_250[1])\n",
    "cv2.imshow(\"TTZI1_240\",TTZI_240[1])\n",
    "cv2.imshow(\"TTZI1_220\",TTZI_220[1])\n",
    "cv2.imshow(\"TTZI1_200\",TTZI_200[1])\n",
    "cv2.imshow(\"TTZI1_180\",TTZI_180[1])\n",
    "cv2.imshow(\"TTZI1_160\",TTZI_160[1])\n",
    "cv2.imshow(\"TTZI1_140\",TTZI_140[1])\n",
    "cv2.imshow(\"TTZI1_120\",TTZI_120[1])\n",
    "cv2.imshow(\"TTZI1_100\",TTZI_100[1])\n",
    "cv2.imshow(\"TTZI1_80\",TTZI_80[1])\n",
    "cv2.imshow(\"TTZI1_50\",TTZI_50[1])\n",
    "cv2.imshow(\"TTZI1_30\",TTZI_30[1])\n",
    "cv2.imshow(\"TTZI1_10\",TTZI_10[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837b4f08",
   "metadata": {},
   "source": [
    "### We can see that in Above Cells that how Different Threshold Value for Simple Thresh To Zero Inverse affects the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490480f5",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a35170",
   "metadata": {},
   "source": [
    "## Comparing The Results of all the Five Simple Thresholding Types(with T =180) on Gray Scale Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37b71080",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Normal Gray Scale Image\",cn1gray)\n",
    "cv2.imshow(\"Thresh Binary\",TB1gray[1])\n",
    "cv2.imshow(\"Thresh Binary Inverse\",TBI1_gray[1])\n",
    "cv2.imshow(\"Thresh Trunc\",TT1_gray[1])\n",
    "cv2.imshow(\"Thresh To Zero\",TZ1_gray[1])\n",
    "cv2.imshow(\"Thresh To Zero Inverse\",TTZI1_gray[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cda5ad1",
   "metadata": {},
   "source": [
    "## Comparing The Results of all the Five Simple Thresholding Types(with T =180) on Colored Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd62b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Colored Image\",cn1color)\n",
    "cv2.imshow(\"Thresh Binary\",TB1color[1])\n",
    "cv2.imshow(\"Thresh Binary Inverse\",TBI1_color[1])\n",
    "cv2.imshow(\"Thresh Trunc\",TT1_color[1])\n",
    "cv2.imshow(\"Thresh To Zero\",TZ1_color[1])\n",
    "cv2.imshow(\"Thresh To Zero Inverse\",TTZI1_color[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ff2ce0",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e459e9",
   "metadata": {},
   "source": [
    "## OTSU Thresholding\n",
    "\n",
    "### As we know in Simple Thresholding we manually provide the Threshold Value(T) and this works well for Images in Controlled Lightning Conditions.\n",
    "\n",
    "### But in Real-world Images where we have no prior Knowledge of the Environment and Lightning Conditions, there we can Automatically compute an Threshold Value using OTSU Thresholding.\n",
    "\n",
    "### Hence ,OTSU Thresholding is an Image Thresholding Technique which assumes that the Gray Scale Histogram of our Image Pixel Intensties is Bi-Modal Or In short means that our image contains only two Classes of Pixels BACKGROUND and FOREGROUND.\n",
    "\n",
    "### Based on the GrayScale Histogram,OTSU Threshold Technique calculates the Optimal Threshold Value(T) such that the Variance between BackGround and ForeGround is Minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "889fd515",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn1_TBO = cv2.threshold(cn1gray,0,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a819956",
   "metadata": {},
   "source": [
    "### We can see that we just Passed Threshold Value(T in Second Argument) as 0 but it will not be used but will be calculated by the OTSU Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9eac24ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185.0,\n",
       " array([[255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255]], dtype=uint8))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn1_TBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d673d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"GrayScale Image\",cn1gray)\n",
    "cv2.imshow(\"Thresh Binary OTSU\",cn1_TBO[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625983b3",
   "metadata": {},
   "source": [
    "### We can see in the Above Cells that we have Performed Binary Otsu Thresholding on Gray Scale Image,and we can see that OTSU Technique calculated The Optimal Threshold Value(T) as 185,and we can also notice that the Reslus are Good and Expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8ab281be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn1_TBIO = cv2.threshold(cn1gray,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "cn1_TTO = cv2.threshold(cn1gray,0,255,cv2.THRESH_TRUNC | cv2.THRESH_OTSU)\n",
    "cn1_TTZO = cv2.threshold(cn1gray,0,255,cv2.THRESH_TOZERO | cv2.THRESH_OTSU)\n",
    "cn1_TTZIO = cv2.threshold(cn1gray,0,255,cv2.THRESH_TOZERO_INV | cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b971a647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185.0,\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn1_TBIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e10e912a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185.0,\n",
       " array([[185, 185, 185, ..., 185, 185, 185],\n",
       "        [185, 185, 185, ..., 185, 185, 185],\n",
       "        [185, 185, 185, ..., 185, 185, 185],\n",
       "        ...,\n",
       "        [185, 185, 185, ..., 185, 185, 185],\n",
       "        [185, 185, 185, ..., 185, 185, 185],\n",
       "        [185, 185, 185, ..., 185, 185, 185]], dtype=uint8))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn1_TTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b12035ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185.0,\n",
       " array([[255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255]], dtype=uint8))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn1_TTZO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dec70f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185.0,\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn1_TTZIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ab73f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Normal Gray Scale Image\",cn1gray)\n",
    "cv2.imshow(\"Thresh Binary OTSU\",cn1_TBO[1])\n",
    "cv2.imshow(\"Thresh Binary Inverse OTSU\",cn1_TBIO[1])\n",
    "cv2.imshow(\"Thresh Trunc OTSU\",cn1_TTO[1])\n",
    "cv2.imshow(\"Thresh To Zero OTSU\",cn1_TTZO[1])\n",
    "cv2.imshow(\"Thresh To Zero Inverse OTSU\",cn1_TTZIO[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b41bca",
   "metadata": {},
   "source": [
    "### We can see that in above cells we perform all types of Simple Thresholding with OTSU Technique and we can notice that:-\n",
    "\n",
    "### -->That OTSU calculates a Single Threshold Value(T) irrespective of the Simple Threshold Technique being used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94971b81",
   "metadata": {},
   "source": [
    "## .)Limitations of OTSU Threshold and Global Thresholding:-\n",
    "\n",
    "### -->`It Doesnot Works Properly with Images that have Noise`:-If Noise is Present in the Image then it reduces the Sharp Valleys between the peaks of the Bi-Modal Histogram.Hence The OTSU or any Global Thresholding Techniques will Fail to segment Properly.\n",
    "\n",
    "### -->`When Images have UnEven Lightning or Illumination Conditions`:-In this case the Pixel Intensity Histogram no longer remains Bi-Modal,Hence the Thresh Value(T) calculated is not Optimal,hence resulting in Bad Segemtation Results. \n",
    "\n",
    "### -->When the ForeGround and BackGround doesnot have Equal Variance.\n",
    "\n",
    "### -->When the Object area is Very Small compared to the BackGround."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30692f7",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b0921c",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297c3384",
   "metadata": {},
   "source": [
    "### Working with Images that fall in the Limitation Categories Describe Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a92486da",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = cv2.imread(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\text1.jpg\")\n",
    "text2 = cv2.imread(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\text2.jpg\")\n",
    "text3 = cv2.imread(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\text3.jpg\")\n",
    "sudoku = cv2.imread(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\sudoku.png\")\n",
    "letters = cv2.imread(r\"E:\\PyImage_ComputerVision\\OpenCVBasic\\WorkingData\\InputData\\letters.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6807fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_gray = cv2.cvtColor(text1,cv2.COLOR_BGR2GRAY)\n",
    "text2_gray = cv2.cvtColor(text2,cv2.COLOR_BGR2GRAY)\n",
    "text3_gray = cv2.cvtColor(text3,cv2.COLOR_BGR2GRAY)\n",
    "sudoku_gray = cv2.cvtColor(sudoku,cv2.COLOR_BGR2GRAY)\n",
    "letters_gray = cv2.cvtColor(letters,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af4c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Text1\",text1_gray)\n",
    "cv2.imshow(\"Text2\",text2_gray)\n",
    "cv2.imshow(\"Text3\",text3_gray)\n",
    "cv2.imshow(\"Suduko\",sudoku_gray)\n",
    "cv2.imshow(\"Letters\",letters_gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fb0e138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_th = cv2.threshold(text1_gray,0,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "text2_th = cv2.threshold(text2_gray,0,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "text3_th = cv2.threshold(text3_gray,0,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "sudoku_th = cv2.threshold(sudoku_gray,0,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "letters_th = cv2.threshold(letters_gray,0,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5fd2c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58.0,\n",
       " array([[255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255]], dtype=uint8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e3a8fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95.0,\n",
       " array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255]], dtype=uint8))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d68d14ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147.0,\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31809670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97.0,\n",
       " array([[255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        ...,\n",
       "        [  0,   0,   0, ..., 255, 255, 255],\n",
       "        [  0,   0,   0, ..., 255, 255, 255],\n",
       "        [  0,   0,   0, ..., 255, 255, 255]], dtype=uint8))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sudoku_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03131564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135.0,\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5846f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Text1 Thresh\",text1_th[1])\n",
    "cv2.imshow(\"Text2 Thresh\",text2_th[1])\n",
    "cv2.imshow(\"Text3 Thresh\",text3_th[1])\n",
    "cv2.imshow(\"Sudoku Thresh\",sudoku_th[1])\n",
    "cv2.imshow(\"letters thresh\",letters_th[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c0d5f",
   "metadata": {},
   "source": [
    "### We can see that in above Cells we used Both Bad Thresholding Results for all the Above Images ,Hence this Demonstrates the Limitation of OTSU and Global Thesholding Techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08036ea",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2721fe",
   "metadata": {},
   "source": [
    "### Now both Simple Thresholding and OTSU Thresholding are `Global Thresholding Technique` which means that same value of T is used to test all the Pixels in the Input Image thus segmenting BackGround and ForeGround Pixels.\n",
    "\n",
    "### This Limitation or Problem can be overcome by using `Adaptive` or `Local Thresholding`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f4842e",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8e213",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f894d081",
   "metadata": {},
   "source": [
    "## Adaptive Thresholding \n",
    "\n",
    "### In Adaptive Thresholding,It considers Small Neighborhood of Pixels and then finds the Optimal Threshold Value(T) for that very Small Neighborhood ,which accounts for Different Threshold Value for Different Regions thus yeilding Better Results for UnEven Lighting and Illumination Conditions.\n",
    "\n",
    "### The General Assumption of Adaptive or Local Thresholding Technique is that Smaller Region of an Image are more likely to have approximately Uniform Illumination.\n",
    "\n",
    "## Mathematics Of Adaptive Thresholding\n",
    "\n",
    "### We use either use Arithmetic Mean or Guassian Mean of the Pixel Intensities in each region to Calculate the Threshold Value(T) of that Region.\n",
    "\n",
    "### -->In Arithmetic Mean each Pixel in the Neighborhood Equally Contributes to calculate Threshold Value(T).\n",
    "### -->In Gaussian Mean the Pixel far from the Center of the Neighborhood contributes Far less than Overall in calculation of Threshold Value(T).\n",
    "\n",
    "### The General Formula of Computing Neighborhood Threshold :-\n",
    "### T = mean - C\n",
    "\n",
    "### Here C is a constant used to Fine Tune the Thresholding Value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e5b8c",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3906f0",
   "metadata": {},
   "source": [
    "### We use `cv2.adaptiveThreshold()` Method to perfrom Adaptive Thresholding in OpenCV.\n",
    "\n",
    "\n",
    "### For `cv2.adaptiveThreshold()` Method:-\n",
    "\n",
    "### < First Argument >:-It takes the NUMPY Array of the Input Image on which we want to perform Adaptive Thresholding.\n",
    "### < Second Argument >:-It takes the Maximum Value that will be used for THRESH Binary and THRESH Binary Inverse Techniques.\n",
    "### < Third Argument >:-It takes the Flag of the ADAPTIVE Thresholding Technique we want to use.\n",
    "### < Fourth Argument >:-It takes the Simple Thresholding Type we want to use.\n",
    "### < Fifth Argument >:-It takes the Block Size which will be the Size of Neighborhood Region we will use in the Adaptive Thresholding Technique.\n",
    "### < Sixth Argument >:-It takes the Value of C which is used to Fine Tune.\n",
    "\n",
    "#### cv2.adaptiveThresholding():-[LINK](https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ga72b913f352e4a1b1b397736707afcde3)\n",
    "\n",
    "#### ADAPTIVE Thresholding FLAGS :-[LINK](https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#gaa42a3e6ef26247da787bf34030ed772c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f5fbea",
   "metadata": {},
   "source": [
    "###  -->Trying Adaptive Thresh Mean :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b033c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 350)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn1gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef0d8b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_5_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,5,1)\n",
    "ad_11_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,1)\n",
    "ad_31_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,31,1)\n",
    "ad_51_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,51,1)\n",
    "ad_71_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,71,1)\n",
    "ad_91_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,91,1)\n",
    "ad_111_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,111,1)\n",
    "ad_131_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,131,1)\n",
    "ad_151_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,151,1)\n",
    "ad_171_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,171,1)\n",
    "ad_191_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,191,1)\n",
    "ad_211_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,211,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bd7848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Simple OTSU Thresholding\",cn1_TBO[1])\n",
    "cv2.imshow(\"AD 5_1\",ad_5_1)\n",
    "cv2.imshow(\"AD 11_1\",ad_11_1)\n",
    "cv2.imshow(\"AD 31_1\",ad_31_1)\n",
    "cv2.imshow(\"AD 51_1\",ad_51_1)\n",
    "cv2.imshow(\"AD 71_1\",ad_71_1)\n",
    "cv2.imshow(\"AD 91_1\",ad_91_1)\n",
    "cv2.imshow(\"AD 111_1\",ad_111_1)\n",
    "cv2.imshow(\"AD 131_1\",ad_131_1)\n",
    "cv2.imshow(\"AD 151_1\",ad_151_1)\n",
    "cv2.imshow(\"AD 171_1\",ad_171_1)\n",
    "cv2.imshow(\"AD 191_1\",ad_191_1)\n",
    "cv2.imshow(\"AD 211_1\",ad_211_1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18237c09",
   "metadata": {},
   "source": [
    "###  We can see in the Above Cells\n",
    "\n",
    "### -->That Less the Block Size more the Details(ForeGround and BackGround) are segmented.\n",
    "### -->On Increasing the Block Size to lose the Details while Segementation.\n",
    "### --> We can see that there are an Optimal Range of Block Sizes between which we can get better Results ,After that range we tend to Lose a lot of Details in Segementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc7b32ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_271_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,271,1)\n",
    "add_281_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,281,1)\n",
    "add_291_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,291,1)\n",
    "add_301_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,301,1)\n",
    "add_311_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,311,1)\n",
    "add_321_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,321,1)\n",
    "add_501_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,501,1)\n",
    "add_1111_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,1111,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3c991f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"AD 271_1\",add_271_1)\n",
    "cv2.imshow(\"AD 281_1\",add_281_1)\n",
    "cv2.imshow(\"AD 291_1\",add_291_1)\n",
    "cv2.imshow(\"AD 301_1\",add_301_1)\n",
    "cv2.imshow(\"AD 311_1\",add_311_1)\n",
    "cv2.imshow(\"AD 321_1\",add_321_1)\n",
    "cv2.imshow(\"AD 501_1\",add_501_1)\n",
    "cv2.imshow(\"AD 1111_1\",add_1111_1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd894b",
   "metadata": {},
   "source": [
    "### The Above Cells were an Experiment to See any Adnormal Behaviour when increasing the Block Size too much \n",
    "\n",
    "### -->It just showed that Bigger the Block Size more the Segementation will be Hurted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a38cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_51_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,51,1)\n",
    "ad_51_7 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,51,7)\n",
    "ad_51_21 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,51,21)\n",
    "ad_51_31 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,51,31)\n",
    "ad_51_41 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,51,41)\n",
    "\n",
    "ad_111_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,111,1)\n",
    "ad_111_21 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,111,21)\n",
    "ad_111_51 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,111,51)\n",
    "ad_111_71 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,111,71)\n",
    "ad_111_99 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,111,99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94727960",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"AD 51_1\",ad_51_1)\n",
    "cv2.imshow(\"AD 51_7\",ad_51_7)\n",
    "cv2.imshow(\"AD 51_21\",ad_51_21)\n",
    "cv2.imshow(\"AD 51_31\",ad_51_31)\n",
    "cv2.imshow(\"AD 51_41\",ad_51_41)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf977f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"AD 111_1\",ad_111_1)\n",
    "cv2.imshow(\"AD 111_21\",ad_111_21)\n",
    "cv2.imshow(\"AD 111_51\",ad_111_51)\n",
    "cv2.imshow(\"AD 111_71\",ad_111_71)\n",
    "cv2.imshow(\"AD 111_99\",ad_111_99)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc8253",
   "metadata": {},
   "source": [
    "### We can see in the Above Cell \n",
    "\n",
    "### --->That on Increasing the C value we start to loss Boundaries and Unnecessary BackGround Noise is added in Foreground.\n",
    "\n",
    "### --->Hence we can notice that we should use Compartibly Very Small Value of C in Relation to the Block Size value.\n",
    "\n",
    "### Example for:-\n",
    "#### ---->For 51 Block Size C can be between 1-7 range.\n",
    "#### ---->For 111 Block Size C can be betweeen 5-21 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e37e47e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_51_51 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,51,51)\n",
    "ad_111_111 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,111,111)\n",
    "ad_51_91 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,51,91) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49e6af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"AD 51_51\",ad_51_51)\n",
    "cv2.imshow(\"AD 111_111\",ad_111_111)\n",
    "cv2.imshow(\"AD 51_91\",ad_51_91)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f0ee2a",
   "metadata": {},
   "source": [
    "### We tried Odd Combination Value of Block Size and  C and got Bad Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77d9982",
   "metadata": {},
   "source": [
    "### -->Trying Adaptive Thresh Gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf9a3c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "adg_5_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,5,1)\n",
    "adg_11_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,1)\n",
    "adg_31_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,31,1)\n",
    "adg_51_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,51,1)\n",
    "adg_71_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,71,1)\n",
    "adg_91_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,91,1)\n",
    "adg_111_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,111,1)\n",
    "adg_131_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,131,1)\n",
    "adg_151_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,151,1)\n",
    "adg_171_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,171,1)\n",
    "adg_191_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,191,1)\n",
    "adg_211_1 = cv2.adaptiveThreshold(cn1gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,211,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fad31102",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Simple OTSU Thresholding\",cn1_TBO[1])\n",
    "cv2.imshow(\"ADG 5_1\",adg_5_1)\n",
    "cv2.imshow(\"ADG 11_1\",adg_11_1)\n",
    "cv2.imshow(\"ADG 31_1\",adg_31_1)\n",
    "cv2.imshow(\"ADG 51_1\",adg_51_1)\n",
    "cv2.imshow(\"ADG 71_1\",adg_71_1)\n",
    "cv2.imshow(\"ADG 91_1\",adg_91_1)\n",
    "cv2.imshow(\"ADG 111_1\",adg_111_1)\n",
    "cv2.imshow(\"ADG 131_1\",adg_131_1)\n",
    "cv2.imshow(\"ADG 151_1\",adg_151_1)\n",
    "cv2.imshow(\"ADG 171_1\",adg_171_1)\n",
    "cv2.imshow(\"ADG 191_1\",adg_191_1)\n",
    "cv2.imshow(\"ADG 211_1\",adg_211_1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db31ef62",
   "metadata": {},
   "source": [
    "###  We can see in the Above Cells\n",
    "\n",
    "### -->That Less the Block Size more the Details(ForeGround and BackGround) are segmented.\n",
    "### -->On Increasing the Block Size to lose the Details while Segementation.\n",
    "### --> We can see that there are an Optimal Range of Block Sizes between which we can get better Results ,After that range we tend to Lose a lot of Details in Segementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48bcdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"AD_51_1\",ad_51_1)\n",
    "cv2.imshow(\"ADG_51_1\",adg_51_1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ff28f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"AD_91_1\",ad_91_1)\n",
    "cv2.imshow(\"ADG_91_1\",adg_91_1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ca2a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"AD_151_1\",ad_151_1)\n",
    "cv2.imshow(\"ADG_151_1\",adg_151_1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc6eb48",
   "metadata": {},
   "source": [
    "### In the Above Cells we compared the Results of the Adaptive Gaussian and Mean (with same Block Size and C Values) and we cann notice that:-\n",
    "\n",
    "### -->Adaptive Gaussian by its defination Segments the Smaller Regions in better ways and is also reluctant to Noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf047e",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9923e41",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c504618b",
   "metadata": {},
   "source": [
    "### -->Now Trying Adaptive Thresholding on the Images where OTSU Failed to perform Better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1424e",
   "metadata": {},
   "source": [
    "### Trying for text2 Image:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a34b0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "736f1626",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2_adt_21_1 = cv2.adaptiveThreshold(text2_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,21,1)\n",
    "text2_adt_11_1 = cv2.adaptiveThreshold(text2_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,1)\n",
    "text2_adt_31_1 = cv2.adaptiveThreshold(text2_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,31,1)\n",
    "text2_adt_51_1 = cv2.adaptiveThreshold(text2_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,51,1)\n",
    "text2_adt_43_1 = cv2.adaptiveThreshold(text2_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,43,1)\n",
    "text2_adt_37_9 = cv2.adaptiveThreshold(text2_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,37,9)\n",
    "text2_adt_35_5 = cv2.adaptiveThreshold(text2_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,35,5)\n",
    "text2_adt_55_21 = cv2.adaptiveThreshold(text2_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,55,21)\n",
    "text2_adt_55_11 = cv2.adaptiveThreshold(text2_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,55,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3f077052",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Gray Scale Image\",text2_gray)\n",
    "cv2.imshow(\"OTSU\",text2_th[1])\n",
    "cv2.imshow(\"21 1\",text2_adt_21_1)\n",
    "cv2.imshow(\"11 1\",text2_adt_11_1)\n",
    "cv2.imshow(\"31 1\",text2_adt_31_1)\n",
    "cv2.imshow(\"51 1\",text2_adt_51_1)\n",
    "cv2.imshow(\"43 1\",text2_adt_43_1)\n",
    "cv2.imshow(\"37 9\",text2_adt_37_9)\n",
    "cv2.imshow(\"35 5\",text2_adt_35_5)\n",
    "cv2.imshow(\"55 25\",text2_adt_55_21)\n",
    "cv2.imshow(\"55 11\",text2_adt_55_11)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d53c9c1",
   "metadata": {},
   "source": [
    "### We can see after Trying with Various Block Size and C values we can see we got the Best Results with 37_9.\n",
    "\n",
    "### --->But we can also Notice that there are some values around Specfic Range which can give us the Good Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c5787eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(691, 1000, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8b9a5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3_ad_61_11 = cv2.adaptiveThreshold(text3_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,61,11)\n",
    "text3_ad_75_25 = cv2.adaptiveThreshold(text3_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,75,25)\n",
    "text3_ad_75_11 = cv2.adaptiveThreshold(text3_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,75,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8de7eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"Normal GrayScale Image\",cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow(\"61 11\",cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow(\"75 25\",cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow(\"75 11\",cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Normal GrayScale Image\",text3_gray)\n",
    "cv2.imshow(\"OTSU Thresholding\",text3_th[1])\n",
    "cv2.imshow(\"61 11\",text3_ad_61_11)\n",
    "cv2.imshow(\"75 11\",text3_ad_75_11)\n",
    "cv2.imshow(\"75 25\",text3_ad_75_25)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c29f51",
   "metadata": {},
   "source": [
    "### We can see after Trying with Various Block Size and C values we can see we got the Best Results with 75_11.\n",
    "\n",
    "### --->But we can also Notice that there are some values around Specfic Range which can give us the Good Results\n",
    "\n",
    "### --->And we can also Notice that High C Values tends to Bad Results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c61566ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(563, 558, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sudoku.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c07ace5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudoku_ad_47_9 = cv2.adaptiveThreshold(sudoku_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,47,9)\n",
    "sudoku_ad_11_9 = cv2.adaptiveThreshold(sudoku_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,1)\n",
    "sudoku_ad_31_13 = cv2.adaptiveThreshold(sudoku_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,31,13)\n",
    "sudoku_ad_47_11 = cv2.adaptiveThreshold(sudoku_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,47,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d41680bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Gray Scale\",sudoku_gray)\n",
    "cv2.imshow(\"OTSU Thresholding\",sudoku_th[1])\n",
    "cv2.imshow(\"47 9\",sudoku_ad_47_9)\n",
    "cv2.imshow(\"11 9\",sudoku_ad_11_9)\n",
    "cv2.imshow(\"31 13\",sudoku_ad_31_13)\n",
    "cv2.imshow(\"47 11\",sudoku_ad_47_11)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd063363",
   "metadata": {},
   "source": [
    "### We can see after Trying with Various Block Size and C values we can see we got the Best Results with 47_11.\n",
    "\n",
    "### --->But we can also Notice that there are some values around Specfic Range which can give us the Good Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5156db1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 318, 3)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0c982d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_ad_11_1 = cv2.adaptiveThreshold(letters_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,1)\n",
    "letters_ad_21_1 = cv2.adaptiveThreshold(letters_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,21,1)\n",
    "letters_ad_27_5 = cv2.adaptiveThreshold(letters_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,27,5)\n",
    "letters_ad_33_1 = cv2.adaptiveThreshold(letters_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,31,1)\n",
    "letters_ad_33_5 = cv2.adaptiveThreshold(letters_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,31,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "36d6e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"GrayScale Image\",letters_gray)\n",
    "cv2.imshow(\"OTSU Threshold\",letters_th[1])\n",
    "cv2.imshow(\"11 1\",letters_ad_11_1)\n",
    "cv2.imshow(\"21 1\",letters_ad_21_1)\n",
    "cv2.imshow(\"27 5\",letters_ad_27_5)\n",
    "cv2.imshow(\"33 1\",letters_ad_33_1)\n",
    "cv2.imshow(\"33 5\",letters_ad_33_5)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2185dc0b",
   "metadata": {},
   "source": [
    "### We can see after Trying with Various Block Size and C values we can see we got the Best Results with 33_5.\n",
    "\n",
    "### --->But we can also Notice that there are some values around Specfic Range which can give us the Good Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0975e4",
   "metadata": {},
   "source": [
    "### Hence we can notice that The Block Size Right Value can be estimated through the Image Size Relation\n",
    "\n",
    "### **NOTE:-There is a Range of Block Size and C Value in which we can get the Best Results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332bda2",
   "metadata": {},
   "source": [
    "## --------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
